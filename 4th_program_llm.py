# -*- coding: utf-8 -*-
"""4th program LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11UiAbr1ZCULXmcKs1Nd_LDDk80HhCQdK

Applications of pre-trained models
4a:Text classification code
"""

import sys
!{sys.executable} -m pip install transformers torch
from transformers import pipeline

# Load a pre-trained sentiment analysis model
classifier = pipeline(
    task="text-classification",
    model="distilbert-base-uncased-finetuned-sst-2-english"
)

# Example texts
texts = [
    "I love using pre-trained models!",
    "This is the worst experience I've ever had."
]

# Perform classification
results = classifier(texts)

# Print results
for text, result in zip(texts, results):
    print(f"Text: {text}")
    print(f"Label: {result['label']}, Confidence: {result['score']:.4f}\n")

"""Applications of pre-trained models
4b:Named entity recognization code
"""

import sys
!{sys.executable} -m pip install transformers torch
from transformers import pipeline

# Load pre-trained NER model
ner_pipeline = pipeline(
    task="ner",
    model="dslim/bert-base-NER",
    aggregation_strategy="simple"
)

# Input text
text = "Santhosh was born in India and was the President of the Bangalore."

# Perform NER
entities = ner_pipeline(text)

# Display results
for entity in entities:
    print(f"Entity: {entity['word']}")
    print(f"Type: {entity['entity_group']}")
    print(f"Confidence: {entity['score']:.4f}\n")

"""Applications of pre-trained models
4c.Question answering code
"""

import sys
!{sys.executable} -m pip install transformers torch
from transformers import pipeline

# Load pre-trained question answering model
qa_pipeline = pipeline(
    task="question-answering",
    model="distilbert-base-cased-distilled-squad"
)

# Context paragraph
context = """
Pre-trained models are trained on large datasets and can be reused for
multiple NLP tasks such as question answering, text classification, and NER.
"""

# Question
question = "What tasks can pre-trained models be used for?"

# Perform question answering
result = qa_pipeline(question=question, context=context)

# Print result
print("Answer:", result["answer"])
print("Confidence:", round(result["score"], 4))

"""Applications of pre-trained models
4d.Text summarization code
"""

import sys
!{sys.executable} -m pip install transformers torch
from transformers import pipeline

# Load pre-trained summarization model
summarizer = pipeline(
    task="summarization",
    model="facebook/bart-large-cnn"
)

# Input text
text = """
Pre-trained models are trained on massive datasets and reused for many
natural language processing tasks such as summarization, translation,
question answering, and text classification. These models significantly
reduce training time and improve performance.
"""

# Generate summary
summary = summarizer(
    text,
    max_length=50,
    min_length=20,
    do_sample=False
)

# Print summary
print("Summary:", summary[0]['summary_text'])